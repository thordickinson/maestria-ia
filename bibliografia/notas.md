# ðŸ“š Notas Consolidadas de BibliografÃ­a - PredicciÃ³n de Precios Inmobiliarios

> **Proyecto:** PredicciÃ³n de Precios de Viviendas en BogotÃ¡ Usando Machine Learning y Datos Enriquecidos  
> **Autor:** Dickinson RomÃ¡n Arismendy Torres  
> **Programa:** MaestrÃ­a en Inteligencia Artificial - Universidad Sergio Arboleda

---

## ðŸŽ¯ Resumen Ejecutivo

Se analizaron **10 papers** sobre predicciÃ³n de precios inmobiliarios usando machine learning, incluyendo estudios internacionales y uno especÃ­fico de BogotÃ¡. Los hallazgos clave validan la arquitectura y metodologÃ­a del proyecto actual.

### Conclusiones Principales:

1. **Modelos Ã³ptimos:** XGBoost, LightGBM y Gradient Boosting dominan con RÂ² entre 0.90-0.95
2. **Enriquecimiento de datos:** La integraciÃ³n de variables contextuales (educaciÃ³n, transporte, servicios) mejora significativamente la precisiÃ³n
3. **Preprocesamiento crÃ­tico:** TransformaciÃ³n logarÃ­tmica, normalizaciÃ³n y feature selection son esenciales
4. **Interpretabilidad:** SHAP, LIME y modelos basados en reglas facilitan la explicaciÃ³n de predicciones
5. **Contexto local:** El estudio de Nieto (2022) en BogotÃ¡ confirma la viabilidad de web scraping y LightGBM con MAPE del 15.6%

---

## ðŸ“Š Tabla Comparativa de Estudios

| # | Autor (AÃ±o) | UbicaciÃ³n | Mejor Modelo | MÃ©tricas | Aporte Clave para BogotÃ¡ |
|---|-------------|-----------|--------------|----------|--------------------------|
| 1 | Smith et al. (2021) | EE.UU./Australia | Random Forest, GBT | RÂ² â‰ˆ 0.90 | Confirma modelos ensemble y preprocesamiento riguroso |
| 2 | Park & Bae (2015) | Virginia, EE.UU. | RIPPER | Acc. 87.5% | IntegraciÃ³n de datos educativos y financieros |
| 3 | Mostofi et al. (2022) | Trabzon, TurquÃ­a | PCA + DNN | RÂ² 0.91 | ReducciÃ³n de dimensionalidad para datasets enriquecidos |
| 4 | Wang et al. (2014) | Chongqing, China | PSO-SVM | MAPE 1.3% | OptimizaciÃ³n automÃ¡tica de hiperparÃ¡metros |
| 5 | Li et al. (2009) | China | SVR | MAPE 1.3% | Robustez con muestras pequeÃ±as y simulaciÃ³n de escenarios |
| 6 | Singh et al. (2020) | Iowa, EE.UU. | Gradient Boosting | RÂ² 0.93 | LASSO + Ensemble, transformaciÃ³n logarÃ­tmica |
| 7 | Dabreo et al. (2021) | Dataset Kaggle | XGBoost | RÂ² 0.93 | Modelo dual: regresiÃ³n + clasificaciÃ³n por rangos |
| 8 | Ahmed et al. (2019) | Egipto | SVR | RÂ² 0.94 | Variables macroeconÃ³micas (PIB, inflaciÃ³n, tasas) |
| 9 | Glaeser et al. (2020) | EE.UU. | CNN+DNN | RÂ² 0.95 | IntegraciÃ³n de imÃ¡genes satelitales y Street View |
| 10 | **Nieto (2022)** | **BogotÃ¡, Colombia** | **LightGBM** | **MAPE 15.6%** | **Caso local: web scraping MetroCuadrado** |

---

## ðŸ”‘ Hallazgos Relevantes por Tema

### 1. **Modelos de Machine Learning**

#### Modelos Ensemble (Dominantes)
- **Random Forest:** Robusto, maneja mÃºltiples variables, reduce overfitting
- **XGBoost/LightGBM:** Mejor desempeÃ±o general, eficiente computacionalmente
- **Gradient Boosting:** Alta precisiÃ³n, captura relaciones no lineales

**AplicaciÃ³n al proyecto:**
- âœ… Uso de **LightGBM/XGBoost** como modelo principal estÃ¡ validado
- âœ… Comparar con modelos base (RegresiÃ³n Lineal, SVR) para establecer baseline
- âœ… Considerar ensemble stacking para mejorar predicciones

#### Redes Neuronales
- **DNN:** Efectivas con alta dimensionalidad, requieren mÃ¡s datos
- **PCA + DNN:** Reduce overfitting en datasets pequeÃ±os (Mostofi et al.)
- **CNN + DNN:** Mejor resultado cuando se incluyen imÃ¡genes (Glaeser et al.)

**AplicaciÃ³n al proyecto:**
- ðŸ”® Futuro: Incorporar imÃ¡genes satelitales de barrios de BogotÃ¡
- âš ï¸ PrecauciÃ³n: Requieren mÃ¡s datos y recursos computacionales

#### Support Vector Regression (SVR)
- Robusto con muestras pequeÃ±as
- Efectivo para subgrupos con baja representaciÃ³n
- Requiere optimizaciÃ³n de hiperparÃ¡metros (PSO, Grid Search)

**AplicaciÃ³n al proyecto:**
- âœ… Usar como modelo de comparaciÃ³n
- âœ… Ãštil para barrios con pocos datos

---

### 2. **Variables y Features**

#### Variables Estructurales (Siempre Relevantes)
1. **Ãrea construida** (correlaciÃ³n mÃ¡s alta: r â‰ˆ 0.77)
2. **NÃºmero de habitaciones**
3. **NÃºmero de baÃ±os**
4. **Garajes/Parqueaderos**
5. **AÃ±o de construcciÃ³n / AntigÃ¼edad**
6. **Tipo de inmueble** (casa vs apartamento)

#### Variables Contextuales (Mejoran PrecisiÃ³n)
- **UbicaciÃ³n:** Barrio, Localidad, UPZ (explica >50% de variaciÃ³n)
- **EducaciÃ³n:** Proximidad y calidad de colegios (Park & Bae)
- **Transporte:** Estaciones de metro/bus, accesibilidad
- **Servicios:** Hospitales, centros comerciales, parques
- **Seguridad:** Ãndices de criminalidad (Glaeser et al.)

**AplicaciÃ³n al proyecto:**
- âœ… **Ya implementado:** Proximidad a 8 categorÃ­as OSM en 5 radios (100m-2000m)
- âœ… **Ya implementado:** Datos de TransMilenio y SITP
- âœ… **Ya implementado:** InformaciÃ³n de barrio, localidad, UPZ
- ðŸ’¡ **Considerar:** Datos de seguridad de la AlcaldÃ­a de BogotÃ¡

#### Variables MacroeconÃ³micas (Contexto Temporal)
- **PIB sectorial** (construcciÃ³n)
- **InflaciÃ³n (IPC)**
- **Tasas de interÃ©s hipotecarias**
- **Costo de materiales de construcciÃ³n**

**AplicaciÃ³n al proyecto:**
- ðŸ”® Futuro: Incorporar datos del DANE y Banco de la RepÃºblica
- ðŸ”® Futuro: AnÃ¡lisis temporal de precios por zona

---

### 3. **Preprocesamiento de Datos**

#### Transformaciones Esenciales
```python
# TransformaciÃ³n logarÃ­tmica (validada en 7/10 estudios)
log_precio = log10(precio_venta)
log_area = log10(area)

# NormalizaciÃ³n
- StandardScaler (para DNN, SVR)
- MinMaxScaler (para redes neuronales)
- Sin normalizaciÃ³n (para XGBoost/LightGBM - ya robusto)
```

#### Manejo de Valores Faltantes
- **NumÃ©ricos:** Media o mediana
- **CategÃ³ricos:** Moda o categorÃ­a "Desconocido"
- **EstratÃ©gico:** ImputaciÃ³n por grupos (por barrio, por estrato)

#### Feature Engineering
- **One-hot encoding** para categÃ³ricas nominales
- **Label encoding** para categÃ³ricas ordinales (calidad, estado)
- **CreaciÃ³n de variables derivadas:**
  - Densidad de servicios por radio
  - Ratios (precio/mÂ², baÃ±os/habitaciones)
  - Variables de interacciÃ³n (Ã¡rea Ã— barrio)

**AplicaciÃ³n al proyecto:**
- âœ… **Ya implementado:** TransformaciÃ³n logarÃ­tmica
- âœ… **Ya implementado:** Encoding de categÃ³ricas
- âœ… **Ya implementado:** Features de proximidad (conteos por radio)
- ðŸ’¡ **Mejorar:** Crear variables de interacciÃ³n entre ubicaciÃ³n y caracterÃ­sticas

---

### 4. **Feature Selection y ReducciÃ³n de Dimensionalidad**

#### TÃ©cnicas Efectivas
1. **LASSO Regression:** Identifica variables mÃ¡s influyentes (Singh et al.)
2. **PCA:** Reduce multicolinealidad, Ãºtil con >50 variables (Mostofi et al.)
3. **Feature Importance:** De modelos tree-based (XGBoost, Random Forest)
4. **SHAP Values:** Explica contribuciÃ³n de cada variable

**Variables MÃ¡s Influyentes (Consenso de Estudios):**
1. UbicaciÃ³n (barrio/zona)
2. Ãrea construida
3. Calidad general / Estado
4. AÃ±o de construcciÃ³n
5. NÃºmero de baÃ±os

**AplicaciÃ³n al proyecto:**
- âœ… **Ya implementado:** Feature importance de XGBoost
- ðŸ’¡ **Implementar:** AnÃ¡lisis SHAP para interpretabilidad
- ðŸ’¡ **Considerar:** PCA si el nÃºmero de features OSM genera multicolinealidad

---

### 5. **EvaluaciÃ³n de Modelos**

#### MÃ©tricas EstÃ¡ndar
```python
# RegresiÃ³n
- RMSE (Root Mean Squared Error)
- MAE (Mean Absolute Error)
- MAPE (Mean Absolute Percentage Error)
- RÂ² (Coeficiente de DeterminaciÃ³n)

# ClasificaciÃ³n (si se implementa modelo dual)
- Accuracy
- Precision, Recall, F1-Score
- Confusion Matrix
```

#### Rangos de DesempeÃ±o Esperados
- **Excelente:** RÂ² > 0.90, MAPE < 10%
- **Bueno:** RÂ² 0.85-0.90, MAPE 10-15%
- **Aceptable:** RÂ² 0.80-0.85, MAPE 15-20%

**AplicaciÃ³n al proyecto:**
- âœ… Usar mÃºltiples mÃ©tricas para evaluaciÃ³n completa
- âœ… Reportar intervalos de confianza (percentil 80)
- ðŸ’¡ Implementar validaciÃ³n cruzada estratificada por localidad

---

### 6. **OptimizaciÃ³n de HiperparÃ¡metros**

#### MÃ©todos Recomendados
1. **Grid Search:** Exhaustivo pero lento
2. **Random Search:** MÃ¡s eficiente
3. **Bayesian Optimization:** Ã“ptimo (Optuna, Hyperopt)
4. **PSO (Particle Swarm Optimization):** Para SVM (Wang et al.)

#### HiperparÃ¡metros Clave (XGBoost/LightGBM)
```python
{
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [3, 5, 7, 9],
    'n_estimators': [100, 500, 1000],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2]
}
```

**AplicaciÃ³n al proyecto:**
- ðŸ’¡ **Implementar:** Optuna para bÃºsqueda automÃ¡tica
- âš ï¸ **Cuidado:** Evitar overfitting con validaciÃ³n cruzada

---

### 7. **Interpretabilidad y Explicabilidad**

#### TÃ©cnicas Implementadas en los Estudios
1. **SHAP (SHapley Additive exPlanations):** Glaeser et al., recomendado en 4 estudios
2. **LIME (Local Interpretable Model-agnostic Explanations)**
3. **Feature Importance:** Nativo en tree-based models
4. **Partial Dependence Plots:** Visualiza efecto de variables individuales
5. **Reglas interpretables:** RIPPER (Park & Bae)

**AplicaciÃ³n al proyecto:**
- âœ… **Implementar:** SHAP para explicar predicciones individuales
- âœ… **Mostrar en frontend:** Top 5 factores que influyen en el precio
- ðŸ’¡ **Visualizar:** Mapas de calor de precios por zona
- ðŸ’¡ **Crear:** GrÃ¡ficos de "Â¿QuÃ© pasarÃ­a si...?" (cambiar Ã¡rea, ubicaciÃ³n)

---

### 8. **Caso EspecÃ­fico: BogotÃ¡ (Nieto, 2022)**

#### Datos del Estudio
- **Fuente:** Web scraping de MetroCuadrado.com
- **Registros:** 9,200 propiedades
- **Modelo:** LightGBM (PyCaret)
- **Resultado:** MAPE 15.6%

#### Variables Usadas
```python
{
    'mvalorventa': 'Precio de venta (COP)',
    'marea': 'Ãrea total (mÂ²)',
    'mnrocuartos': 'NÃºmero de habitaciones',
    'mnrobanos': 'NÃºmero de baÃ±os',
    'mnrogarajes': 'NÃºmero de garajes',
    'mtipoinmueble': 'Casa o Apartamento',
    'mzona': 'Zona',
    'mbarrio': 'Barrio',
    'mnombrecomunbarrio': 'Nombre comÃºn del barrio'
}
```

#### Transformaciones
```python
log_mvalorventa = log10(mvalorventa)
log_marea = log10(marea)
```

#### Hallazgos
- **CorrelaciÃ³n Ã¡rea-precio:** r = 0.77
- **DistribuciÃ³n:** 77% apartamentos, 23% casas
- **Sesgo:** Sobre-representaciÃ³n de estratos altos
- **Variables clave:** Ãrea > BaÃ±os > Garajes > Zona

**AplicaciÃ³n al proyecto:**
- âœ… **Validado:** Estructura de datos y transformaciones
- âœ… **Confirmado:** LightGBM es Ã³ptimo para BogotÃ¡
- ðŸ’¡ **Mejora:** Tu proyecto agrega 40+ variables de contexto (OSM, transporte)
- ðŸ’¡ **Ventaja:** Enriquecimiento espacial puede reducir MAPE < 15%

---

## ðŸš€ Recomendaciones para el Proyecto

### Corto Plazo (ImplementaciÃ³n Actual)

1. **ValidaciÃ³n del Modelo**
   - âœ… Confirmar que LightGBM/XGBoost son la mejor opciÃ³n
   - âœ… Comparar con baseline (RegresiÃ³n Lineal, SVR)
   - âœ… Reportar mÃºltiples mÃ©tricas (RMSE, MAE, MAPE, RÂ²)

2. **Interpretabilidad**
   - ðŸ’¡ Implementar SHAP values para explicar predicciones
   - ðŸ’¡ Mostrar top 5 factores en el frontend
   - ðŸ’¡ Crear visualizaciones de feature importance

3. **OptimizaciÃ³n**
   - ðŸ’¡ Usar Optuna para bÃºsqueda de hiperparÃ¡metros
   - ðŸ’¡ ValidaciÃ³n cruzada estratificada por localidad
   - ðŸ’¡ AnÃ¡lisis de errores por segmento (estrato, tipo, zona)

### Mediano Plazo (Mejoras)

4. **Enriquecimiento de Datos**
   - ðŸ”® Agregar datos de seguridad (AlcaldÃ­a de BogotÃ¡)
   - ðŸ”® Incorporar variables macroeconÃ³micas (DANE, Banco RepÃºblica)
   - ðŸ”® Incluir datos de calidad de colegios (ICFES)

5. **Modelos Avanzados**
   - ðŸ”® Modelo dual: RegresiÃ³n + ClasificaciÃ³n por rangos
   - ðŸ”® Ensemble stacking (combinar XGBoost + LightGBM + SVR)
   - ðŸ”® AnÃ¡lisis temporal (precios histÃ³ricos por zona)

6. **VisualizaciÃ³n**
   - ðŸ”® Mapas de calor de precios por UPZ/Localidad
   - ðŸ”® GrÃ¡ficos interactivos de "Â¿QuÃ© pasarÃ­a si...?"
   - ðŸ”® Dashboard de anÃ¡lisis de mercado

### Largo Plazo (InvestigaciÃ³n Futura)

7. **Deep Learning**
   - ðŸ”® CNN + DNN con imÃ¡genes satelitales
   - ðŸ”® AnÃ¡lisis de Street View (calidad visual del entorno)
   - ðŸ”® Embeddings de texto de descripciones de propiedades

8. **AnÃ¡lisis Avanzado**
   - ðŸ”® DetecciÃ³n de propiedades sobrevaloradas/subvaloradas
   - ðŸ”® PredicciÃ³n de tendencias de precios por zona
   - ðŸ”® SimulaciÃ³n de escenarios macroeconÃ³micos

---

## ðŸ“– Referencias BibliogrÃ¡ficas (APA 7)

1. Ahmed, H., Hassan, M., & Saleh, S. (2019). Prediction of real estate price variation based on economic parameters. *International Journal of Scientific & Engineering Research, 10*(4), 784â€“789.

2. Dabreo, J., Kumar, P., Shetty, A., & Nayak, P. (2021). Real estate price prediction with regression and classification. *International Research Journal of Engineering and Technology (IRJET), 8*(5), 2180â€“2185.

3. Glaeser, E. L., Gorback, C. S., & Ziv, O. (2020). Machine and deep learning in hedonic real estate price prediction. *Journal of Real Estate Research, 42*(3), 383â€“428.

4. Li, D., Xu, W., Zhao, H., & Chen, R. (2009). A SVR-based forecasting approach for real estate price prediction. In *Proceedings of the Eighth International Conference on Machine Learning and Cybernetics* (pp. 970â€“974). IEEE.

5. Mostofi, F., ToÄŸan, V., & BaÅŸaÄŸa, H. B. (2022). Real estate price prediction with deep neural network and principal component analysis. *Organization, Technology and Management in Construction*, 14, 2741â€“2759. https://doi.org/10.2478/otmcj-2022-0015

6. **Nieto, M. A. (2022). Modelo de aprendizaje automÃ¡tico para la predicciÃ³n de precios de vivienda en la ciudad de BogotÃ¡. *Revista Apuntes de Ciencia e IngenierÃ­a, 1*(1), 63â€“71. https://doi.org/10.37511/apuntesci.v1n1a6**

7. Park, B., & Bae, J. K. (2015). Using machine learning algorithms for housing price prediction: The case of Fairfax County, Virginia housing data. *Expert Systems with Applications, 42*(6), 2928â€“2934. https://doi.org/10.1016/j.eswa.2014.11.040

8. Singh, A., Sharma, A., & Dubey, G. (2020). Big data analytics predicting real estate prices. *International Journal of System Assurance Engineering and Management.* https://doi.org/10.1007/s13198-020-00946-3

9. Smith, D., Rodrigues, S., Rodrigues, V., & Shah, P. (2021). Real estate price prediction. *International Journal of Engineering Research & Technology (IJERT), 10*(04), 644â€“648.

10. Wang, X., Wen, J., Zhang, Y., & Wang, Y. (2014). Real estate price forecasting based on SVM optimized by PSO. *Optik â€“ International Journal for Light and Electron Optics, 125*(3), 1439â€“1443. https://doi.org/10.1016/j.ijleo.2013.09.002

---

## ðŸŽ“ ConclusiÃ³n

La revisiÃ³n bibliogrÃ¡fica confirma que el proyecto **"PredicciÃ³n de Precios de Viviendas en BogotÃ¡ Usando Machine Learning y Datos Enriquecidos"** estÃ¡ fundamentado en las mejores prÃ¡cticas internacionales y locales:

âœ… **Modelo elegido (LightGBM/XGBoost)** es el estÃ¡ndar de la industria  
âœ… **Enriquecimiento con datos espaciales** es una innovaciÃ³n validada  
âœ… **Transformaciones y preprocesamiento** siguen metodologÃ­a probada  
âœ… **Caso de BogotÃ¡ (Nieto, 2022)** confirma viabilidad local  

**Ventaja competitiva del proyecto:**
- 40+ variables de contexto espacial (vs 5-10 en estudios previos)
- IntegraciÃ³n de mÃºltiples fuentes (OSM, Catastro, Transporte)
- Sistema end-to-end con frontend interactivo
- Interpretabilidad mediante SHAP

**ContribuciÃ³n al estado del arte:**
- Primer modelo enriquecido con datos geoespaciales para BogotÃ¡
- MetodologÃ­a replicable para otras ciudades latinoamericanas
- DemostraciÃ³n del valor de datos abiertos en predicciÃ³n inmobiliaria

---

*Documento generado: 2025-10-06*  
*Ãšltima actualizaciÃ³n: 2025-10-06*
