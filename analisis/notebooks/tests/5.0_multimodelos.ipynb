{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b9ee03-bfe8-472d-a241-b9af9d48651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# PIPELINE GENERAL: evaluación múltiple de modelos (Base/Aumentado)\n",
    "# ===========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    root_mean_squared_error\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e0ebb-e39d-48c7-8f1a-15a68245e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpretar_rmse_log(rmse_log, df, target_col=\"precio_venta\"):\n",
    "    \"\"\"Convierte RMSE en logaritmos a error porcentual y pesos COP.\"\"\"\n",
    "    precio_medio = df[target_col].mean()\n",
    "    error_pct = np.exp(rmse_log) - 1\n",
    "    error_pesos = precio_medio * error_pct\n",
    "    return error_pct, error_pesos, precio_medio\n",
    "\n",
    "\n",
    "def evaluar_modelos(df, nombre_dataset=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Evalúa múltiples modelos de regresión sobre el dataset dado.\n",
    "    Retorna DataFrame con métricas y diccionario con modelos entrenados.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n=== Evaluando {nombre_dataset} ===\")\n",
    "\n",
    "    # ------------------------------\n",
    "    # 1️⃣ Preparar datos\n",
    "    # ------------------------------\n",
    "    target = \"precio_venta_log\"\n",
    "    ignore_cols = [\"precio_venta\", \"precio_venta_log\", \"sector\", \"localidad_calculada\"]\n",
    "    features = [c for c in df.columns if c not in ignore_cols]\n",
    "\n",
    "    X = df[features].copy()\n",
    "    y = df[target].copy()\n",
    "\n",
    "    # ------------------------------\n",
    "    # 2️⃣ Preprocesamiento\n",
    "    # ------------------------------\n",
    "    numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ------------------------------\n",
    "    # 3️⃣ Definir modelos\n",
    "    # ------------------------------\n",
    "    modelos = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"Lasso\": Lasso(alpha=0.1, max_iter=10000),\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"RandomForest\": RandomForestRegressor(\n",
    "            n_estimators=200, random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        # \"SVR\": SVR(kernel=\"rbf\", C=10, epsilon=0.2),\n",
    "        \"XGBoost\": XGBRegressor(\n",
    "            n_estimators=500, learning_rate=0.05, max_depth=6,\n",
    "            subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        \"LightGBM\": LGBMRegressor(\n",
    "            n_estimators=500, learning_rate=0.05, max_depth=-1,\n",
    "            subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # ------------------------------\n",
    "    # 4️⃣ Validación cruzada\n",
    "    # ------------------------------\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    scoring = {\n",
    "        \"RMSE\": make_scorer(root_mean_squared_error, greater_is_better=False),\n",
    "        \"MAE\": make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        \"R2\": make_scorer(r2_score)\n",
    "    }\n",
    "\n",
    "    resultados = []\n",
    "    modelos_entrenados = {}\n",
    "\n",
    "    # ------------------------------\n",
    "    # 5️⃣ Entrenar y evaluar\n",
    "    # ------------------------------\n",
    "    for nombre, modelo in modelos.items():\n",
    "        print(f\"Entrenando modelo: {nombre} ...\")\n",
    "        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", modelo)])\n",
    "\n",
    "        cv_result = cross_validate(\n",
    "            pipeline, X, y, cv=kf, scoring=scoring, n_jobs=-1, return_train_score=False\n",
    "        )\n",
    "\n",
    "        rmse_log = -np.mean(cv_result[\"test_RMSE\"])\n",
    "        mae_log = -np.mean(cv_result[\"test_MAE\"])\n",
    "        r2_mean = np.mean(cv_result[\"test_R2\"])\n",
    "        error_pct, error_pesos, precio_medio = interpretar_rmse_log(rmse_log, df)\n",
    "\n",
    "        resultados.append({\n",
    "            \"Dataset\": nombre_dataset,\n",
    "            \"Modelo\": nombre,\n",
    "            \"RMSE log\": rmse_log,\n",
    "            \"MAE log\": mae_log,\n",
    "            \"R²\": r2_mean,\n",
    "            \"Error %\": error_pct * 100,\n",
    "            \"Error medio (COP)\": error_pesos,\n",
    "            \"Precio medio (COP)\": precio_medio\n",
    "        })\n",
    "\n",
    "        # Entrenar el modelo completo para guardarlo\n",
    "        pipeline.fit(X, y)\n",
    "        modelos_entrenados[nombre] = pipeline\n",
    "\n",
    "    # ------------------------------\n",
    "    # 6️⃣ Resultados\n",
    "    # ------------------------------\n",
    "    resultados_df = pd.DataFrame(resultados).sort_values(by=\"RMSE log\")\n",
    "    print(\"\\n=== Resultados de evaluación ===\")\n",
    "    print(resultados_df[[\"Modelo\", \"RMSE log\", \"R²\", \"Error %\", \"Error medio (COP)\"]].round(3))\n",
    "\n",
    "    return resultados_df, modelos_entrenados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4111b-8bc7-4faf-9dd0-7a70f183cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# EJEMPLO DE USO\n",
    "# ===========================================================\n",
    "# result_base, modelos_base = evaluar_modelos(df_base, \"Modelo Base\")\n",
    "# result_enriched, modelos_enriched = evaluar_modelos(df_enriched, \"Modelo Aumentado\")\n",
    "\n",
    "# comparacion = pd.concat([result_base, result_enriched])\n",
    "# print(\"\\n=== Comparación entre datasets ===\")\n",
    "# print(comparacion.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
