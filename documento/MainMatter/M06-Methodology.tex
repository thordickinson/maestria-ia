\section{Construcción, evaluación e interpretabilidad de los modelos}

El proceso de modelado se organizó en tres configuraciones principales: un \textbf{modelo base} con variables exclusivamente estructurales, un \textbf{modelo enriquecido} que incorpora información geoespacial y administrativa, y un \textbf{modelo enriquecido optimizado} construido a partir de un subconjunto reducido de variables seleccionadas con SHAP. En los tres casos se empleó validación cruzada de diez pliegues y se realizaron búsquedas de hiperparámetros específicas para XGBoost dentro de un mismo espacio de configuración, descrito en la Tabla~\ref{tab:xgb_param_search}. 

La métrica de entrenamiento y comparación entre modelos fue el \textbf{RMSE} calculado sobre el \textit{logaritmo natural del precio de venta}. De forma complementaria, y únicamente con fines de interpretabilidad, se calculó el error en \textbf{pesos colombianos (COP)} aplicando la transformación inversa a las predicciones y a los valores reales (\texttt{np.expm1}). Estas validaciones en pesos permitieron cuantificar el error absoluto y relativo por rango de precios, pero no se utilizaron para ajustar ni seleccionar los modelos.

%--------------------------------------------------
\subsection{Modelo base: variables estructurales}

El modelo base se entrenó utilizando únicamente variables estructurales del inmueble (área, baños, parqueaderos, estrato, antigüedad, estado, administración) y las coordenadas geográficas. Como punto de partida se compararon varios algoritmos de regresión: Linear Regression, Ridge, Lasso, Random Forest, LightGBM y XGBoost. La Tabla~\ref{tab:modelos_base_log} resume el desempeño promedio en validación cruzada de diez pliegues sobre la variable transformada \texttt{precio\_venta\_log}. No se seleccionaron modelos de caja negra como redes neuronales porque también se busca obtener interpretabilidad.

\begin{table}[ht]
\centering
\small
\caption{Comparación inicial de algoritmos de regresión para el modelo base (10-Fold CV, escala logarítmica).}
\label{tab:modelos_base_log}
\begin{tabular}{lrrrr}
\hline
\textbf{Modelo} & \textbf{RMSE medio} & \textbf{RMSE std} & \textbf{MAE medio} & \textbf{$R^2$ medio} \\
\hline
XGBoost           & 0.1359 & 0.0022 & 0.1018 & 0.9515 \\
LightGBM          & 0.1386 & 0.0023 & 0.1040 & 0.9495 \\
Random Forest     & 0.1400 & 0.0025 & 0.0994 & 0.9485 \\
Ridge             & 0.2245 & 0.0073 & 0.1706 & 0.8674 \\
Linear Regression & 0.2245 & 0.0073 & 0.1706 & 0.8674 \\
Lasso             & 0.2821 & 0.0056 & 0.2230 & 0.7909 \\
\hline
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\small
\caption{Espacio de búsqueda de hiperparámetros utilizado para XGBoost.}
\label{tab:xgb_param_search}
\begin{tabular}{p{3.8cm} p{3cm} p{7.2cm}}
\hline
\textbf{Hiperparámetro} & \textbf{Rango} & \textbf{Justificación} \\
\hline
\texttt{n\_estimators} & [200, 500] & Controla el número de árboles y limita la complejidad y el tiempo de entrenamiento. \\[2pt]

\texttt{max\_depth} & [3, 7] & Profundidades moderadas capturan no linealidades sin producir árboles muy sobreajustados. \\[2pt]

\texttt{learning\_rate} & [0.02, 0.06] & Tasas pequeñas estabilizan el aprendizaje y favorecen la generalización del modelo. \\[2pt]

\texttt{subsample} & [0.7, 0.9] & Reduce varianza y correlación entre árboles del ensamble. \\[2pt]

\texttt{colsample\_bytree} & [0.7, 0.9] & Genera árboles más diversos y controla el sobreajuste. \\[2pt]

\texttt{min\_child\_weight} & [1, 6] & Evita divisiones en nodos con muy pocas observaciones y reduce particiones ruidosas. \\[2pt]

\texttt{gamma} & [0.0, 2.0] & Exige una reducción mínima de la pérdida para aceptar nuevas particiones en los árboles. \\[2pt]
\hline
\end{tabular}
\end{table}


Dado su mejor desempeño y estabilidad, se seleccionó \textbf{XGBoost} como algoritmo base, utilizando la función de pérdida por defecto para regresión (\texttt{reg:squarederror}). Para este modelo se ejecutó una búsqueda aleatoria de hiperparámetros (\texttt{RandomizedSearchCV}) dentro del espacio descrito en la Tabla~\ref{tab:xgb_param_search}, manteniendo constante el \textit{pipeline} de preprocesamiento.

\begin{table}[ht]
\centering
\small
\caption{Mejores hiperparámetros de XGBoost por configuración de modelo.}
\label{tab:xgb_best_params}
\begin{tabular}{lccc}
\hline
\textbf{Hiperparámetro} & \textbf{Base} & \textbf{Enriquecido} & \textbf{Optimizado} \\
\hline
\texttt{n\_estimators}      & 488    & 488    & 397    \\
\texttt{max\_depth}         & 6      & 6      & 5      \\
\texttt{learning\_rate}     & 0.0319 & 0.0319 & 0.0341 \\
\texttt{subsample}          & 0.8302 & 0.8302 & 0.6666 \\
\texttt{colsample\_bytree}  & 0.7587 & 0.7587 & 0.7943 \\
\texttt{min\_child\_weight} & 3      & 3      & 9      \\
\texttt{gamma}              & 0.0282 & 0.0282 & 1.0010 \\
\texttt{reg\_lambda}        & 2.3526 & 2.3526 & 2.2522 \\
\texttt{reg\_alpha}         & 0.3030 & 0.3030 & 0.5086 \\
\hline
\end{tabular}
\end{table}

En el modelo base, la validación cruzada de diez pliegues produjo los siguientes resultados promedio (escala logarítmica):

\begin{itemize}
    \item \textbf{RMSE}: 0.1424 \ (\textit{std} = 0.0029)
    \item \textbf{MAE}: 0.1064 \ (\textit{std} = 0.0020)
    \item \textbf{$R^{2}$}: 0.9467 \ (\textit{std} = 0.0035)
\end{itemize}

\subsubsection{Validación cruzada en pesos para el modelo base}

Para aportar interpretabilidad en términos monetarios, se repitió la validación cruzada aplicando la transformación inversa a la variable objetivo. En cada pliegue se entrenó el mismo \textit{pipeline} sobre \texttt{precio\_venta\_log}, se obtuvieron las predicciones \texttt{y\_pred\_log} y luego se transformaron a pesos con \texttt{np.expm1}, tanto para las predicciones como para los valores reales. Con estos valores se calcularon RMSE y MAE en COP por pliegue.

Los resultados agregados fueron:

\begin{itemize}
    \item \textbf{RMSE promedio en COP}: \$106.35 millones \ (\textit{std} = \$2.90 millones)
    \item \textbf{MAE promedio en COP}: \$70.43 millones \ (\textit{std} = \$1.54 millones)
\end{itemize}

La Figura~\ref{fig:error_base_absoluto} muestra la distribución del \textbf{error absoluto} en pesos por rango de precios, mientras que la Figura~\ref{fig:error_base_relativo} presenta el \textbf{error relativo}, evidenciando que, aunque el error absoluto aumenta con el precio del inmueble, el error relativo se mantiene por debajo de 0.1 en la mayoría de rangos, lo que respalda la estabilidad del modelo en términos proporcionales.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\linewidth]{Images/metodologia/analisis_error_base_absoluto.png}
    \caption{Distribución del error absoluto del modelo base en pesos colombianos.}
    \label{fig:error_base_absoluto}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\linewidth]{Images/metodologia/analisis_error_base_relativo.png}
    \caption{Distribución del error relativo del modelo base por rango de precios.}
    \label{fig:error_base_relativo}
\end{figure}

%--------------------------------------------------
\subsection{Modelo enriquecido: incorporación de variables geoespaciales}

El \textbf{modelo enriquecido} incorporó las variables geoespaciales y administrativas derivadas del proceso descrito en la sección de enriquecimiento: identificadores de barrio, UPZ y localidad, avalúos catastrales y 45 variables de conteo de POIs en cinco radios y ocho categorías. El preprocesamiento se mantuvo mediante el mismo \texttt{ColumnTransformer} del modelo base, y se reutilizó el espacio de búsqueda de hiperparámetros resumido en la Tabla~\ref{tab:xgb_param_search}. La búsqueda produjo los mismos hiperparámetros óptimos que en el modelo base (Tabla~\ref{tab:xgb_best_params}), lo cual facilita la comparación al mantener fija la configuración del algoritmo y variar únicamente el conjunto de variables.

La validación cruzada de diez pliegues para el modelo enriquecido arrojó:

\begin{itemize}
    \item \textbf{RMSE promedio}: 0.1494 \ (\textit{std} = 0.00627)
    \item \textbf{MAE promedio}: 0.1123 \ (\textit{std} = 0.00397)
    \item \textbf{$R^{2}$ promedio}: 0.9387 \ (\textit{std} = 0.01069)
\end{itemize}

\subsubsection{Validación cruzada en pesos para el modelo enriquecido}

Repitiendo la estrategia de convertir las predicciones de logaritmos a pesos, se obtuvo:

\begin{itemize}
    \item \textbf{RMSE promedio en COP}: \$112.86 millones \ (\textit{std} = \$4.22 millones)
    \item \textbf{MAE promedio en COP}: \$76.05 millones \ (\textit{std} = \$2.46 millones)
\end{itemize}

En términos absolutos, el modelo enriquecido presenta errores ligeramente superiores a los del modelo base, tanto en la escala logarítmica como en pesos, a pesar de incorporar un número considerable de variables adicionales.

%--------------------------------------------------
\subsection{Modelo enriquecido optimizado: selección de variables con SHAP}

Con el fin de analizar la contribución marginal de cada variable y reducir la complejidad del modelo enriquecido, se aplicó \textbf{SHAP} (\textit{SHapley Additive exPlanations}) sobre el modelo XGBoost entrenado con todas las variables geoespaciales y estructurales. A partir de los valores SHAP absolutos promedio, se identificó un subconjunto de características con mayor importancia global.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.65\linewidth]{Images/metodologia/shap_enriched_summary.png}
    \caption{Resumen de importancias SHAP del modelo enriquecido.}
    \label{fig:shap_enriched_summary}
\end{figure}

La Figura~\ref{fig:shap_enriched_summary} muestra que la señal predictiva se concentra principalmente en variables estructurales y de localización, mientras que la mayoría de variables derivadas de POIs presentan impactos cercanos a cero en la predicción individual. Sobre esta base se seleccionó el conjunto reducido de predictores utilizado en el modelo enriquecido optimizado.

Las diez características con mayor \textit{mean absolute SHAP} fueron:

\begin{itemize}
    \item \textbf{Área} (\texttt{num\_\_area})
    \item \textbf{Latitud} (\texttt{num\_\_latitud})
    \item \textbf{Número de parqueaderos} (\texttt{num\_\_parqueaderos})
    \item \textbf{Longitud} (\texttt{num\_\_longitud})
    \item \textbf{Cuota de administración} (\texttt{num\_\_administracion})
    \item \textbf{Número de baños} (\texttt{num\_\_banos})
    \item \textbf{Antigüedad} (categorías \texttt{ENTRE 0 Y 5 ANOS}, \texttt{MAS DE 20 ANOS})
    \item \textbf{Gimnasio} (\texttt{num\_\_gimnasio})
    \item \textbf{Número de habitaciones} (\texttt{num\_\_habitaciones})
    \item \textbf{Ascensor} (\texttt{num\_\_ascensor})
\end{itemize}

A partir de estas variables se definió el \textbf{modelo enriquecido optimizado}. Se mantuvo el mismo \textit{pipeline} de preprocesamiento y el mismo espacio de búsqueda de hiperparámetros, obteniendo la configuración específica mostrada en la Tabla~\ref{tab:xgb_best_params}.

La validación cruzada de diez pliegues produjo:

\begin{itemize}
    \item \textbf{RMSE promedio}: 0.1480 \ (\textit{std} = 0.0058)
    \item \textbf{MAE promedio}: 0.1096 \ (\textit{std} = 0.0031)
    \item \textbf{$R^{2}$ promedio}: 0.9400 \ (\textit{std} = 0.0095)
\end{itemize}

\subsubsection{Validación cruzada en pesos para el modelo optimizado}

Aplicando de nuevo la conversión a pesos:

\begin{itemize}
    \item \textbf{RMSE promedio en COP}: \$107.23 millones \ (\textit{std} = \$3.37 millones)
    \item \textbf{MAE promedio en COP}: \$70.99 millones \ (\textit{std} = \$2.11 millones)
\end{itemize}

Las Figuras~\ref{fig:error_opt_absoluto} y~\ref{fig:error_opt_relativo} muestran el comportamiento del error absoluto y relativo del modelo optimizado en función del precio del inmueble. Se observa un patrón similar al del modelo base: el error absoluto crece con el valor del inmueble, pero el error relativo se mantiene acotado y en rangos comparables.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\linewidth]{Images/metodologia/analisis_error_enriquecido_optimizado_absoluto.png}
    \caption{Distribución del error absoluto del modelo enriquecido optimizado en pesos colombianos.}
    \label{fig:error_opt_absoluto}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\linewidth]{Images/metodologia/analisis_error_enriquecido_optimizado_relativo.png}
    \caption{Distribución del error relativo del modelo enriquecido optimizado por rango de precios.}
    \label{fig:error_opt_relativo}
\end{figure}

%--------------------------------------------------
\subsection{Comparación estadística y selección del modelo final}

Para evaluar si las diferencias de desempeño entre modelos eran estadísticamente significativas, se aplicaron pruebas t de Student pareadas sobre los valores de RMSE obtenidos en cada uno de los diez pliegues:

\begin{itemize}
    \item \textbf{Modelo base vs. modelo enriquecido}:\\
    RMSE medio base = 0.1424, RMSE medio enriquecido = 0.1494,\\
    $t = -2.91$, $p = 0.0174$ $\Rightarrow$ diferencia significativa (\(p < 0.05\)).
    
    \item \textbf{Modelo enriquecido vs. modelo optimizado}:\\
    RMSE medio enriquecido = 0.1494, RMSE medio optimizado = 0.1480,\\
    $t = 2.87$, $p = 0.0186$ $\Rightarrow$ diferencia significativa (\(p < 0.05\)).
    
    \item \textbf{Modelo base vs. modelo optimizado}:\\
    RMSE medio base = 0.1424, RMSE medio optimizado = 0.1480,\\
    $t = -2.43$, $p = 0.0378$ $\Rightarrow$ diferencia significativa (\(p < 0.05\)).
\end{itemize}

La Tabla~\ref{tab:comparacion_modelos_millones} resume el desempeño de los tres modelos en términos de error medio en pesos colombianos.

\begin{table}[ht]
\centering
\small
\caption{Comparación de desempeño entre configuraciones de modelo (10-Fold CV, valores medios en millones de pesos).}
\label{tab:comparacion_modelos_millones}
\begin{tabular}{lcccc}
\hline
\textbf{Modelo} & \textbf{RMSE (M\$)} & \textbf{RMSE std (M\$)} & \textbf{MAE (M\$)} & \textbf{MAE std (M\$)} \\
\hline
Base                    & 106.35 & 2.90 & 70.43 & 1.54 \\
Enriquecido             & 112.86 & 4.22 & 76.05 & 2.46 \\
Enriquecido optimizado  & 107.23 & 3.37 & 70.99 & 2.11 \\
\hline
\end{tabular}
\end{table}

En conjunto, los resultados muestran que:

\begin{itemize}
    \item El \textbf{modelo base} alcanza el menor RMSE tanto en la escala logarítmica como en pesos y presenta la mayor estabilidad entre pliegues.
    \item El \textbf{modelo enriquecido} introduce más variables, pero empeora el error medio y la varianza del desempeño.
    \item El \textbf{modelo enriquecido optimizado} reduce el ruido del modelo enriquecido eliminando variables de baja importancia, pero no logra superar la precisión del modelo base.
\end{itemize}

Por estas razones, y dado que el objetivo principal es obtener un modelo preciso y estable para la estimación de precios, se seleccionó el \textbf{modelo base con XGBoost} como modelo final para su despliegue en la aplicación web descrita en la siguiente sección. Las configuraciones enriquecidas se utilizaron principalmente como soporte para el análisis de la influencia del contexto geoespacial y para la discusión sobre la redundancia de información espacial en relación con variables estructurales y de localización.

\section{Implementación del sistema web}

El sistema desarrollado integra un \textbf{backend en FastAPI}, una base de datos \textbf{PostgreSQL con PostGIS} y una interfaz \textbf{frontend en ReactJS}. Su propósito es permitir que un usuario ingrese la información básica de un inmueble y obtenga, en tiempo real, una estimación de precio junto con estadísticas del entorno urbano. La Figura~\ref{fig:arquitectura_sistema} presenta una vista general de la arquitectura implementada.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{Images/metodologia/arquitectura_app.png}
    \caption{Arquitectura general del sistema web desarrollado.}
    \label{fig:arquitectura_sistema}
\end{figure}


Durante la fase de preparación de datos, el conjunto de propiedades utilizado para el entrenamiento del modelo fue enriquecido con información geográfica y posteriormente se generaron \textbf{estadísticos agregados por barrio, UPZ y localidad}, incluyendo valores promedio de área, administración, estrato y precio estimado. Estos datos derivados se almacenaron en la base de datos PostgreSQL para permitir su recuperación eficiente cuando el usuario consulta la aplicación. Adicionalmente, el modelo final (enriquecido optimizado) fue exportado a un archivo \texttt{.pkl}, lo que facilita su carga y ejecución dentro del backend sin necesidad de reconstruir el pipeline completo en cada solicitud.

El backend recibe las solicitudes provenientes del frontend y ejecuta tres tareas principales: (i) geocodificación de la dirección ingresada mediante el servicio Nominatim; (ii) asignación automática de barrio y UPZ utilizando consultas espaciales en PostGIS; y (iii) ejecución del modelo optimizado para generar la estimación de precio. La respuesta enviada al frontend incluye tanto la predicción como un conjunto de métricas contextuales del sector, obtenidas directamente desde las tablas agregadas precomputadas en la base de datos.

En la aplicación frontend, la interacción inicia con un formulario donde el usuario ingresa las características físicas del inmueble (área, baños, parqueaderos, antigüedad, estrato y administración). En una segunda pantalla se solicita la \textbf{dirección}, que es geocodificada automáticamente para obtener las coordenadas iniciales. Estas coordenadas se muestran en un mapa interactivo implementado con \texttt{Leaflet}, permitiendo al usuario mover el marcador manualmente para ajustar la ubicación con mayor precisión si lo desea.

Una vez confirmados los datos, la aplicación presenta un \textbf{reporte interactivo}. Este reporte incluye:  
(1) un mapa con los puntos de interés cercanos al inmueble en distintos radios de distancia;  
(2) una tabla con los conteos de POIs por categoría y radio;  
(3) comparaciones visuales entre las características del inmueble y los promedios del barrio, la UPZ y la localidad;  
(4) gráficos que resumen estadísticas relevantes del entorno urbano.  
Ejemplos de estas visualizaciones se muestran en las Figuras~\ref{fig:reporte_mapa_pois} y~\ref{fig:comparacion_estadisticas}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\linewidth]{Images/metodologia/reporte_mapa.png}
    \caption{Vista del reporte generado: mapa con puntos de interés cercanos.}
    \label{fig:reporte_mapa_pois}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\linewidth]{Images/metodologia/reporte_comparativa_barrio.png}
    \caption{Comparativa entre las características del inmueble y los promedios del barrio y la UPZ.}
    \label{fig:comparacion_estadisticas}
\end{figure}

Este diseño permite que el modelo predictivo se integre en una plataforma accesible y comprensible para el usuario final, ofreciendo no solo una estimación numérica sino una contextualización completa del entorno urbano, lo cual facilita la interpretación del resultado y mejora la utilidad práctica del sistema en escenarios de consulta inmobiliaria.
