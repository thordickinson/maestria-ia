## ‚öôÔ∏è **Paper 4: Wang, Wen, Zhang & Wang (2014) ‚Äì Real Estate Price Forecasting Based on SVM Optimized by PSO**

**Referencia completa:**
Wang, X., Wen, J., Zhang, Y., & Wang, Y. (2014). *Real Estate Price Forecasting Based on SVM Optimized by PSO.* *Optik ‚Äì International Journal for Light and Electron Optics,* 125(3), 1439‚Äì1443.
[https://doi.org/10.1016/j.ijleo.2013.09.002](https://doi.org/10.1016/j.ijleo.2013.09.002)

---

### üìò **Contexto general**

El estudio aborda uno de los problemas m√°s frecuentes en los modelos predictivos de precios inmobiliarios: **la dificultad de ajustar los hiperpar√°metros del modelo de Support Vector Machine (SVM)**.
Para resolverlo, los autores proponen un enfoque h√≠brido donde la **optimizaci√≥n de par√°metros (C, Œµ, Œ≥)** del SVM se realiza mediante el algoritmo **Particle Swarm Optimization (PSO)**, una t√©cnica de inteligencia de enjambres inspirada en el comportamiento colectivo de aves o peces.

Este enfoque busca alcanzar **mayor precisi√≥n con menos iteraciones** y sin necesidad de ajustes manuales.

---

### üß© **Datos utilizados**

* **Ubicaci√≥n:** Chongqing, China.
* **Fuente:** Datos del mercado inmobiliario local recopilados entre 2005 y 2012.
* **Tipo de datos:** Series temporales trimestrales de precios promedio de vivienda.
* **Variables utilizadas:**

  1. Ingreso per c√°pita disponible.
  2. √çndice de precios al consumidor (CPI).
  3. Inversi√≥n en desarrollo inmobiliario.
  4. Tasa de inter√©s promedio anual.
  5. Precio hist√≥rico de vivienda (retardo temporal).
* **Tama√±o del conjunto:** 40 registros trimestrales (30 para entrenamiento, 10 para prueba).

---

### ‚öôÔ∏è **Metodolog√≠a**

#### 1. **Modelo de base: SVM (Support Vector Machine)**

El SVM se usa en su versi√≥n de **regresi√≥n (SVR)**, que busca encontrar una funci√≥n que prediga los precios con el menor error dentro de un margen Œµ (epsilon-insensitive loss function).

La precisi√≥n de este modelo depende de tres hiperpar√°metros:

* **C:** penalizaci√≥n por error (control de regularizaci√≥n).
* **Œµ:** margen de tolerancia de error.
* **Œ≥:** par√°metro del kernel RBF (define la forma de la funci√≥n de similitud).

---

#### 2. **Optimizaci√≥n con PSO (Particle Swarm Optimization)**

El algoritmo PSO se aplica para encontrar autom√°ticamente los valores √≥ptimos de estos hiperpar√°metros.
Cada ‚Äúpart√≠cula‚Äù representa una combinaci√≥n posible de (C, Œµ, Œ≥), y se eval√∫a con base en el RMSE del modelo SVR.

**Procedimiento:**

1. Inicializaci√≥n aleatoria de part√≠culas en el espacio de b√∫squeda.
2. Evaluaci√≥n del desempe√±o del SVR para cada part√≠cula.
3. Actualizaci√≥n de velocidades y posiciones seg√∫n la mejor soluci√≥n global y local.
4. Iteraci√≥n hasta converger al m√≠nimo RMSE.

---

#### 3. **Comparaciones realizadas**

Se compararon tres modelos:

* **PSO‚ÄìSVM (propuesto)**
* **SVM convencional (sin optimizaci√≥n)**
* **Red neuronal BP (Backpropagation Neural Network)**

---

### üìä **Resultados principales**

| Modelo          | MAE      | MAPE     | RMSE     | R¬≤       | Comentarios                                 |
| --------------- | -------- | -------- | -------- | -------- | ------------------------------------------- |
| **PSO‚ÄìSVM**     | **1.36** | **1.3%** | **1.89** | **0.96** | Mejor desempe√±o global.                     |
| SVM est√°ndar    | 1.78     | 1.7%     | 2.48     | 0.91     | Precisi√≥n media, sensible al ajuste manual. |
| Red neuronal BP | 2.10     | 2.2%     | 2.79     | 0.87     | Sobreajuste y menor estabilidad.            |

**Hallazgos clave:**

* La optimizaci√≥n autom√°tica mediante PSO **mejor√≥ entre 25‚Äì30 % el rendimiento del SVM**.
* El modelo h√≠brido logr√≥ capturar **patrones no lineales y dependencias temporales** del mercado.
* Menor error y convergencia m√°s r√°pida comparado con b√∫squeda manual o algoritmos gen√©ticos.

---

### üß† **Conclusiones**

* El modelo **PSO‚ÄìSVM** supera a las redes neuronales tradicionales y al SVM sin optimizaci√≥n.
* La **optimizaci√≥n metaheur√≠stica** (PSO) es una alternativa eficaz para seleccionar hiperpar√°metros en modelos complejos.
* Este enfoque permite adaptarse a mercados inmobiliarios con alta volatilidad o relaciones no lineales entre variables econ√≥micas.
* Los autores destacan que este m√©todo puede extenderse a predicciones espaciales y no solo temporales.

---

### üåé **Aportes y relevancia para Bogot√°**

| Aspecto                                        | Aplicaci√≥n en tu proyecto                                                                                                                  |
| ---------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| **Optimizaci√≥n autom√°tica de hiperpar√°metros** | Puedes aplicar un enfoque similar usando **Optuna, Hyperopt o Bayesian Optimization** para optimizar XGBoost/LightGBM sin b√∫squeda manual. |
| **Variables macroecon√≥micas**                  | Sugiere la posibilidad de incluir indicadores externos como **tasas de inter√©s hipotecarias o IPC** en tu modelo para enriquecer contexto. |
| **Series temporales**                          | Aunque tu modelo no es temporal, podr√≠as extenderlo a un an√°lisis longitudinal (precios hist√≥ricos por barrio).                            |
| **Eficiencia computacional**                   | El PSO demostr√≥ reducir el tiempo de b√∫squeda; esto es √∫til si planeas iterar sobre grandes combinaciones de par√°metros.                   |
| **Control de sobreajuste**                     | Refuerza la importancia de ajustar par√°metros de regularizaci√≥n (learning rate, depth, gamma) en LightGBM/XGBoost.                         |

---

### üìñ **Cita sugerida (APA 7):**

Wang, X., Wen, J., Zhang, Y., & Wang, Y. (2014). *Real estate price forecasting based on SVM optimized by PSO.* *Optik ‚Äì International Journal for Light and Electron Optics, 125*(3), 1439‚Äì1443. [https://doi.org/10.1016/j.ijleo.2013.09.002](https://doi.org/10.1016/j.ijleo.2013.09.002)
