# analisis/notebooks/1.2.analisis_limpieza_imputacion.ipynb

## Procedimiento paso a paso

1. Carga de `../data/aptos_bogota.csv` generado en 1.1; inspección con `info()` y `describe()`.
2. Revisión de nulos por columna y detección de anomalías en numéricas (`area`, `precio_venta`, `parqueaderos`, `estrato`, `numero_piso`) y coordenadas.
3. Visualizaciones exploratorias:
   - Distribuciones y boxplots de `area` y `precio_venta`.
   - Distribución de categóricas (`estrato`, `sector`, `estado`, `antiguedad`).
4. Tratamiento de outliers extremos (percentil 99):
   - Umbrales: `area<=464`, `precio_venta<=5.4e9` → filtrado a `df_clean`.
5. Eliminación de precios de venta inválidos: `precio_venta < 50,000,000`.
6. Imputación de `area` cuando es 0:
   - Mediana por comparables (mismo `estrato`,`habitaciones`,`banos`,`sector`), si no hay, mediana por `estrato`.
7. Corrección de `parqueaderos` negativos:
   - Reemplazo por moda de `parqueaderos` en el mismo `estrato` (o moda general si no hay).
8. Validación/corrección de coordenadas:
   - Detección de lat/lon fuera de Bogotá.
   - Imputación por mediana del `sector`; si `sector` nulo, por mediana global.
   - Filtrado final a bounding box aproximado Bogotá: `lat∈[4.4,4.9]`, `lon∈[-74.3,-73.9]`.
9. Revisión de `estrato` fuera de rango [1–6] y tentativa de imputación por modo del `sector` (con advertencias benignas de indexación); persistencia de algunos casos para tratamiento posterior.
10. Correlaciones y relaciones con `precio_venta` (heatmap; boxplot por estrato; scatter `area` vs `precio_venta`).
11. Visualización de proporción de amenidades binarias.
12. Resultado: dataset limpio `df_clean` listo para imputaciones complementarias/modelado en notebooks posteriores.

## Notas
- Produce `df_clean` en memoria; el guardado de una versión imputada completa puede ocurrir en notebooks siguientes (no mostrado aquí).
