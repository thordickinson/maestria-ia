# analisis/notebooks/3.2.0.modelo_datos_aumentados_v0.ipynb

## Procedimiento paso a paso

1. Carga de `../data/aptos_bogota_enriched.csv` y renombres: `estrato_calculado→estrato`, `barrio_calculado→barrio`, `upz_calculada→upz`; eliminación de filas con `barrio` nulo.
2. Imputación por barrio (función `imputar_por_barrio`):
   - `administracion` (media), `estado` (moda), `upz` (moda), `catastral` (media), `comercial` (media), `antiguedad` (moda).
3. División train/holdout (20%).
4. Selección de `features` (excluye `precio_venta`, `sector`, `localidad_calculada`).
5. Preprocesamiento:
   - Numéricas: `SimpleImputer(median)`; para `area` aplica log con `FunctionTransformer` tras imputación mediana.
   - Categóricas: `SimpleImputer(most_frequent)` + `OneHotEncoder`.
6. Modelo: `XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1)`.
7. Entrenamiento del pipeline completo sobre `y = log(precio_venta)`.
8. Importancia de variables:
   - Obtiene nombres expandidos (numéricas + dummies) y grafica top 30.
   - Observación: las variables originales (log(area), parqueaderos, administración, baños, antigüedad) dominan; aparecen algunas enriquecidas y dummies de barrio con menor peso.
9. Conclusiones preliminares: señal principal en variables estructurales; las enriquecidas aportan marginalmente o su efecto está capturado por `barrio`.
