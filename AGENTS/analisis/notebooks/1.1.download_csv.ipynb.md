# analisis/notebooks/1.1.download_csv.ipynb

## Procedimiento paso a paso

1. Importación de librerías: `pandas`, `numpy`, `seaborn`, `matplotlib`, `plotly.express`, `geohash`, `requests`, `os`.
2. Utilidad: `print_cols()` para visualizar columnas en grupos.
3. Descarga de datos crudos JSON desde GitHub Releases al path `../data/raw_data.json` (crea carpeta si no existe).
4. Carga del JSON con `pd.read_json()` en `raw_json_ds` y exploración con `head()`/`info()`.
5. Depuración inicial: eliminación de columnas irrelevantes (`_id`, `codigo`, `datetime`, `url`, `direccion`, `website`, `compañia`, `timeline`, `last_view`, `descripcion`, `imagenes`).
6. Normalización de campos tipo dict (números envueltos):
   - Funciones `get_first_property()` y `unpack_dict()` para convertir a `int`/`float`/`str`.
   - Conversiones aplicadas: `precio_venta`→float, `administracion`→float, `precio_arriendo`→float.
7. Filtrado por tipo: creación de `apartamentos = properties[properties['tipo_propiedad'] == 'APARTAMENTO']`.
8. Filtrado por operación: `aptos_venta = apartamentos[apartamentos['tipo_operacion'].str.contains('VENTA', ...)]`.
9. Selección de variables relevantes: `drop(['tipo_operacion','tipo_propiedad','precio_arriendo'])`.
10. Remoción de registros sin `precio_venta`: `dropna(subset=['precio_venta'])`.
11. Extracción de características a partir de `caracteristicas` (lista de tags):
    - Tags booleanos mapeados a columnas: `alarma`, `ascensor`, `conjunto_cerrado`, `gimnasio`, `piscina`, `zona_de_bbq` (además se analizaron otros y se descartaron por muy baja frecuencia: `aire_acondicionado`, `balcon`, `se_permiten_mascotas`).
    - Patrones numéricos extraídos con regex: `area_terraza`, `numero_piso`, `numero_closets` (se intentó `area_lote`, pero se descartó por 100% nulos).
12. Análisis de cobertura de nuevas columnas y decisión:
    - `area_lote`: 100% nula → se elimina.
    - `area_terraza`: ~25% cobertura → se conserva.
    - `numero_piso`: ~68% cobertura → se conserva.
    - `numero_closets`: ~36% cobertura → se conserva.
13. Balanceo de clases de booleanas y decisiones de mantener/descartar según frecuencia y relevancia.
14. Limpieza final: eliminación de la columna original `caracteristicas` tras descomposición.
15. Verificación de tipos y nulos en el dataset resultante `aptos_venta_caracteristicas`.
16. Exportaciones:
    - Dataset completo: `../data/aptos_bogota.csv` (UTF-8).
    - Muestra reproducible: `../data/aptos_bogota_sample.csv` (100 filas, `random_state=42`).

## Notas
- Este notebook genera el dataset base para EDA y modelado en los siguientes notebooks.
- Requiere conectividad a internet para la descarga inicial del JSON.
