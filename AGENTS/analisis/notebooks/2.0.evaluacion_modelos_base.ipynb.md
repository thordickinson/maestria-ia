# analisis/notebooks/2.0.evaluacion_modelos_base.ipynb

## Procedimiento paso a paso

1. Carga de `../data/aptos_bogota_imputed.csv` (dataset limpio/imputado); define `target = 'precio_venta'`.
2. Filtrado de variables por umbral de nulos (≤5%): construye `cols_to_use` y crea `X`, `y`.
3. Tipificación automática de columnas numéricas/categóricas.
4. Preprocesamiento con `ColumnTransformer`:
   - Numéricas: `SimpleImputer(mean)` + `StandardScaler`.
   - Categóricas: `SimpleImputer(most_frequent)` + `OneHotEncoder(handle_unknown='ignore')`.
5. Comparación de modelos base con `KFold(n_splits=5)` midiendo `RMSE` (scoring negativo en `sklearn`):
   - Modelos: Linear, Ridge, Lasso, KNN, DecisionTree, RandomForest, SVR, XGBoost, LightGBM.
   - Resultado: RF/XGBoost/LightGBM obtienen los mejores RMSE (muy cercanos); SVR pobre desempeño.
6. Importancia de variables (RandomForest):
   - Entrena pipeline RF y extrae importancias con nombres expandidos (tras OneHot).
   - Exporta a `importancia_variables_rf.csv`.
7. Evaluación con features reducidas (top-N importancias):
   - Repite comparación con subconjunto reducido.
8. Evaluación con transformación logarítmica:
   - Aplica `np.log1p` al target y al feature `area` (mediante `FunctionTransformer`).
   - Compara modelos y reporta `RMSE`, `MAE`, `R²`, `MAPE` retransformados a escala original.
9. Entrenamiento final (hold-out 20%) con RandomForest y exportación del pipeline:
   - Reporta métricas de hold-out (RMSE≈250M, R²≈0.915, etc.).
   - Exporta a `../data/models/randomforest_model_base.pkl` usando `cloudpickle`.

## Salidas
- `importancia_variables_rf.csv`
- `perm_importance_rf.csv` (desde análisis de permutación)
- `../data/models/randomforest_model_base.pkl`
